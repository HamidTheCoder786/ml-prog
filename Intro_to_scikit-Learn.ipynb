{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction To Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  reading the data and getting it ready \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart=pd.read_csv(\"heart.csv\")\n",
    "heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  creating a features matrix\n",
    "x=heart.drop(\"target\",axis=1)\n",
    "\n",
    "#  creating a label matrix \n",
    "y=heart[\"target\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is a hyperparameter ?\n",
    "\n",
    "* It is a fine tuning parameter for a working ml model eg, like adjusting the speed of a fan .\n",
    "\n",
    "Choosing the right model and hyperparameters \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "#  we are using the default hyperparameters of RandomForest()\n",
    "# clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Fit the model to the training data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train , x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(x_train,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  predicting the data\n",
    "y_preds=clf.predict(x_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  evaluating the model on training data \n",
    "clf.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf.score(x_test,y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RandomForestClassifier obtains a 88.5% accuracy in test data without changing any hyperparameters of RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
    "print(classification_report(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improving the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "for i in range(10,100,10):\n",
    "    print(f\"trying model with {i} estimators \\n\")\n",
    "    clf=RandomForestClassifier(n_estimators=i).fit(x_train,y_train)\n",
    "    print(f\"\\n Model accuracy on test set:{clf.score(x_test,y_test)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "pickle.dump(clf,open(\"RandomForestClassifiermodel1.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model=pickle.load(open(\"RandomForestClassifiermodel1.pkl\",\"rb\"))\n",
    "load_model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting our data ready \n",
    "\n",
    "Three main things to be done \n",
    "\n",
    "* Splitting data into features and labels (usually `x` & `y`)\n",
    "\n",
    "* Filling(imputing) our  missing data or to drop missing data\n",
    "\n",
    "* Converting non-numerical values to numerical values (feature encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=heart.drop(\"target\",axis=1)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=heart[\"target\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2)\n",
    "xtrain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing feature encoding on a data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car=pd.read_csv(\"carext.csv\")\n",
    "car.head()\n",
    "car\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=car.drop(\"Price\",axis=1)\n",
    "y=car[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,train_size=0.2)\n",
    "xtest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code throws an error as there are strings present on the dataset and a ml model can't work on a string hence an error is observed \n",
    "\n",
    "```\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "reg=RandomForestRegressor()\n",
    "reg.fit(xtrain,ytrain)\n",
    "reg.score(xtest,ytest)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categoricalfeatures=[\"Make\",\"Colour\",\"Doors\"]\n",
    "onehot=OneHotEncoder()\n",
    "transformer=ColumnTransformer([(\"onehot\",onehot,categoricalfeatures)],remainder=\"passthrough\")\n",
    "transformedx=transformer.fit_transform(x)\n",
    "transformedx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(transformedx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'car' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dummies\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mget_dummies(car[[\u001b[39m\"\u001b[39m\u001b[39mMake\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mColour\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mDoors\u001b[39m\u001b[39m\"\u001b[39m]])\n\u001b[1;32m      2\u001b[0m dummies\n",
      "\u001b[0;31mNameError\u001b[0m: name 'car' is not defined"
     ]
    }
   ],
   "source": [
    "dummies=pd.get_dummies(car[[\"Make\",\"Colour\",\"Doors\"]])\n",
    "dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  OneHotEncoder method and pd.get_dummies method give the same result however it is upto the coder which method he wants to use  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CamelCase --> first letter of every word is capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refitting the model \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model=RandomForestRegressor()\n",
    "\n",
    "np.random.seed(42)\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(transformedx,y,test_size=0.2)\n",
    "model.fit(xtrain,ytrain)\n",
    "model.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the above model is able to predict to an accuracy of about 33 % which is not acceptable and needs the hyperparameters to be fine tuned "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with missing values in a data set. There are 2 ways:\n",
    "* Filling the missing value of  data set with some value also known as imputation\n",
    "* Removing the missing value altogether "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the missing dataset \n",
    "carmiss=pd.read_csv(\"carmissext.csv\")\n",
    "carmiss.head()\n",
    "carmiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carmiss.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=carmiss.drop(\"Price\",axis=1)\n",
    "y=carmiss[\"Price\"]\n",
    "# pd.Series([\"honda\",\"audi\",\"bmw\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are using sklearn version 1.2 which can handle Nan values by itself and does not raises an exception hence the code written in cell below the print works fine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categoricalfeatures=[\"Make\",\"Colour\",\"Doors\"]\n",
    "onehot=OneHotEncoder()\n",
    "transformer=ColumnTransformer([(\"onehot\",onehot,categoricalfeatures)],remainder=\"passthrough\")\n",
    "transformedx=transformer.fit_transform(x)\n",
    "transformedx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carmiss.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1: Filling the Missing data using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carmiss[\"Make\"].fillna(\"missing\",inplace=True)\n",
    "carmiss[\"Colour\"].fillna(\"missing\",inplace=True)\n",
    "carmiss[\"Doors\"].fillna(4,inplace=True)\n",
    "carmiss[\"Odometer (KM)\"].fillna(carmiss[\"Odometer (KM)\"].mean(),\n",
    "inplace=True)\n",
    "# carmiss[\"Price\"].fillna(carmiss[\"Price\"])\n",
    "carmiss.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Rows with missing price values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carmiss.dropna(inplace=True)\n",
    "carmiss.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(carmiss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=carmiss.drop(\"Price\",axis=1)\n",
    "y=carmiss[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categoricalfeatures=[\"Make\",\"Colour\",\"Doors\"]\n",
    "onehot=OneHotEncoder()\n",
    "transformer=ColumnTransformer([(\"onehot\",onehot,categoricalfeatures)],remainder=\"passthrough\")\n",
    "transformedx=transformer.fit_transform(x)\n",
    "transformedx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling missing data with scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carmiss=pd.read_csv(\"carmiss2.csv\")\n",
    "carmiss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carmiss.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carmiss.dropna(subset=[\"Price\"],inplace=True)\n",
    "carmiss.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=carmiss.drop(\"Price\",axis=1)\n",
    "y=carmiss[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "#  cat stands for categorical \n",
    "#  num stands for numerical \n",
    "\n",
    "catimputer=SimpleImputer(strategy=\"constant\",fill_value=\"missing\")\n",
    "doorimputer=SimpleImputer(strategy=\"constant\",fill_value=4)\n",
    "numimputer=SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "catfeatures=[\"Make\",\"Colour\"]\n",
    "doorfeatures=[\"Doors\"]\n",
    "numfeatures=[\"Odometer (KM)\"]\n",
    "\n",
    "imputr=ColumnTransformer([\n",
    "    (\"catimputer\",catimputer,catfeatures),\n",
    "    (\"doorimputer\",doorimputer,doorfeatures),\n",
    "    (\"numimputer\",numimputer,numfeatures)\n",
    "])\n",
    "filledx=imputr.fit_transform(x)\n",
    "filledx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carfilled=pd.DataFrame(filledx,columns=[\"make\",\"colour\",\"doors\",\"odometer\"])\n",
    "carfilled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carfilled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categoricalfeatures=[\"make\",\"colour\",\"doors\"]\n",
    "onehot=OneHotEncoder()\n",
    "transformer=ColumnTransformer([(\"onehot\",onehot,categoricalfeatures)],remainder=\"passthrough\")\n",
    "transformedx=transformer.fit_transform(carfilled)\n",
    "transformedx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(transformedx,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestRegressor()\n",
    "clf.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the RandomForestRegressor used gives us an accuracy of about 22 % which is unacceptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(xtest,ytest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the righ model \\ algorithm \\ estimators:\n",
    "\n",
    "Some things to note:\n",
    "\n",
    "* sklearn refer ml models\\ algorithms as estimators\n",
    "* Classification problem - predicting a category (heart disease or not) \n",
    "    * `clf` is used for classifier as shortform\n",
    "* Regression problem - predicting a number (price of a house)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"housing.csv\")\n",
    "data.head()\n",
    "data=data.dropna()\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "np.random.seed(42)\n",
    "x=data.drop(\"median_house_value\",axis=1)\n",
    "y=data[\"median_house_value\"]\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2)\n",
    "model=Ridge()\n",
    "model.fit(xtrain,ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Ridge model provides an accuracy of 64 % which is not acceptable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Using RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "np.random.seed(42)\n",
    "model= RandomForestRegressor()\n",
    "model.fit(xtrain,ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RandomForestRegressor gives us an accuracy of about 83 % which is acceptable but can use some hyperparameter tuning to boost performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Problem\n",
    "On heart dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(heart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "np.random.seed(42)\n",
    "x=heart.drop([\"target\"],axis=1)\n",
    "y=heart[\"target\"]\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2)\n",
    "clf=LinearSVC(max_iter=10000000)\n",
    "clf.fit(x,y)\n",
    "clf.score(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(xtest,ytest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the LinearSVC model gives us an accuracy of around 73 % which needs to be improved after increasing the vlaue of max iter we get around 88 % accuracy which is acceptable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier()\n",
    "x=heart.drop([\"target\"],axis=1)\n",
    "y=heart[\"target\"]\n",
    "np.random.seed(42)\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2)\n",
    "clf.fit(xtrain,ytrain)\n",
    "clf.score(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we observed an overfitting of data when evaluating the score of training data where as we observe an accuracy of 85 % in RandomForestClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eventhough the accuracy of LinearSVC is more than RandomForestClassifier by about 3% the time taken to train the LinearSVC is about 1 min 30 sec where as that of RandomForestClassifier is about 0.7 s hence we would prefer the RandomForestClassifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions with help of a ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds=clf.predict(xtest)\n",
    "np.mean(y_preds==ytest) # --> just a fancy way for using clf.score() function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(ytest,y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions with `predict_proba()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict_proba(xtest[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in the above output the `predict_proba()` returns an array of which the left column denotes the probablity of 0 value where as right column denotes the probablity of 1 value of target. The probablity can never be greater than 1 in any case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(xtest[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "np.random.seed(42)\n",
    "model=RandomForestRegressor()\n",
    "x=data.drop(\"median_house_value\",axis=1)\n",
    "y=data[\"median_house_value\"]\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2)\n",
    "model.fit(xtrain,ytrain)\n",
    "model.score(xtrain,ytrain)\n",
    "ypreds=model.predict(xtest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict_proba(xtest[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ypreds=model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "ytest,ypreds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ypreds),len(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(ytest,ypreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating an ML model :\n",
    "Three ways to do :\n",
    "* `score()`\n",
    "* `scoring` parameter\n",
    "* problem specific metric\n",
    "\n",
    "\n",
    "* clf=RandomForestClassifier(n_estimators=100000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart=pd.read_csv(\"heart.csv\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier()\n",
    "x= heart.drop([\"target\"],axis=1)\n",
    "y=heart[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x.dropna()\n",
    "y=y.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2)\n",
    "clf.fit(xtrain,ytrain)\n",
    "clf.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(clf,x,y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the `cross_val_score()` returns an array of score trained and tested on different portions of data  the greater the value of `cv` in function more we can clearly figure out the true potential of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(clf,x,y,cv=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(xtest,ytest),np.mean(cross_val_score(clf,x,y,cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the `clf` model is `np.mean(cross_val_score(clf,x,y,cv=10))` "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# area under reciever operating  charctersistic curve (AUC \\ ROC)\n",
    "\n",
    "* Simply it is the comparision between true positive rate (tpr) and false positive rate (fpr)\n",
    "\n",
    "* True positive rate : model predicts `1` when target is `1`\n",
    "\n",
    "* False positive rate : model predicts `1` when target is `0`\n",
    "\n",
    "* True negative rate : model predicts `0` when target is `0`\n",
    "\n",
    "* False negative rate : model predicts `0` when target is `1`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier()\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2)\n",
    "clf.fit(xtrain,ytrain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "ypreds=clf.predict_proba(xtest)\n",
    "ypreds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypos=ypreds[:,1]\n",
    "ypos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  calculating tpr ,fpr & threshold\n",
    "fpr,tpr,thrs=roc_curve(ytest,ypos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.plot(fpr,tpr)\n",
    "def PlotROCCurve(fpr,tpr):\n",
    "    \"\"\" \n",
    "    This function plots the ROC curve if tpr and fpr is provided\n",
    "    \"\"\"\n",
    "    #  plotting the model \n",
    "    plt.plot(fpr,tpr,color=\"green\",label=\"ROC\")\n",
    "\n",
    "    # plotting the layman guess \n",
    "\n",
    "    plt.plot([0,1],[0,1],color=\"red\",linestyle=\"--\",label=\"Guessing\")\n",
    "\n",
    "    # customizing the graph\n",
    "    plt.xlabel(\"false positive rate (fpr) \")\n",
    "    plt.ylabel(\"true positve rate (tpr)\")\n",
    "    plt.title(\"Recviever Operating Characteristic (ROC) Curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "PlotROCCurve(fpr,tpr)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(ytest,ypos) # --> a score of 94.8 % is obtained "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `roc_auc_score()` provides the area enclosed by the curve obtained in the `PlotROCCurve()` function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr,tpr,thrs=roc_curve(ytest,ypos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotROCCurve(fpr,tpr) # -->graph obtained is same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  plotting the perfect ROC graph\n",
    "fpr,tpr,thrs=roc_curve(ytest,ytest)\n",
    "\n",
    "PlotROCCurve(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  the above graph obtained has an `roc_auc_score()` of 1.0 i.e. it is perfect\n",
    "roc_auc_score(ytest,ytest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "ypreds=clf.predict(xtest)\n",
    "confusion_matrix(ypreds,ytest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The anti principal diagonal elements(off diagonal) of a `confusion_matrix` are `fpr`\n",
    "and `fnr ` respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(ytest,\n",
    "ypreds,\n",
    "rownames=[\"actual value\"],\n",
    "colnames=[\"predicted values\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  creating a visual confusion matrix with help of seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "cmat=confusion_matrix(ytest,ypreds)\n",
    "\n",
    "sns.heatmap(cmat);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(estimator=clf,X=x,y=y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(ytest,ypreds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest,ypreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "housing=pd.read_csv(\"housing.csv\")\n",
    "x=housing.drop(housing[\"target\"],axis=1)\n",
    "y=housing[\"target\"\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "40 8:36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01aaf8047257313ac93d98d42ebb941deb25f14b68fc8d4fddbeb658838499eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
